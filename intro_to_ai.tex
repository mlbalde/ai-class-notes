\documentclass[10pt,a4paper]{article}
\usepackage[utf8x]{inputenc}
\usepackage{ucs}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{rotating}
\usepackage{color}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{multicol}

\newtheorem{defin}{Definition}
\newtheorem{ex}{Example}

% Draws a cylinder with "DB" in the middle
\newsavebox{\DB}
\savebox{\DB}{
\qbezier(0,30)(15,25)(30,30)
\qbezier(0,30)(15,35)(30,30)
\qbezier(0,5)(15,0)(30,5)
\put(0,5){\line(0,1){25}}
\put(30,5){\line(0,1){25}}
\put(6,12){\large DB}
}

% Draws a small stick figure
\newsavebox{\stickman}
\savebox{\stickman}{
\put(5,20){\circle{8}}
\put(5,16){\line(0,-1){12}}
\put(0,13){\line(1,0){10}}
}

% For drawing the box around nodes at the end of Section 2
\newsavebox{\nodeBox}
\savebox{\nodeBox}{
\put(0,0){\line(0,1){50}}
\put(0,0){\line(1,0){30}}
\put(30,50){\line(-1,0){30}}
\put(30,50){\line(0,-1){50}}
}

\newenvironment{itemize_packed}{
\begin{itemize}
\setlength{\itemsep}{0pt}
\setlength{\parskip}{0pt}
}{\end{itemize}}

\title{Notes for Introduction to Artificial Intelligence}
\begin{document}

%===============================================================================

\part{Welcome to AI}

\begin{defin}[Intelligent Agent]
An \emph{\textbf{Intelligent Agent}} observes the environment using its \emph{\textbf{sensors}}, makes a decision, and affects the environment using its \emph{\textbf{actuators}}.
\end{defin}

\begin{center}
\begin{picture}(200,100)
\thicklines
\put(20,20){\line(1,0){70}}
\put(90,20){\line(0,1){70}}
\put(20,20){\line(0,1){70}}
\put(20,90){\line(1,0){70}}
\put(40,92){Agent}
\put(170,55){\oval(40,90)}
\put(167,88){\begin{rotate}{-90}\large{Environment}\end{rotate}}
\put(158,90){\vector(-4,-1){80}}
\put(80,40){\vector(4,-1){80}}
\put(100,80){\begin{rotate}{15}Sensors\end{rotate}}
\put(100,40){\begin{rotate}{-15}Actuators\end{rotate}}
\color{red}
\put(65,70){\vector(0,-1){30}}
\put(50,50){\LARGE{\textbf{?}}}
\end{picture}
\end{center}


\begin{defin}[Perception-Action Cycle]
The cycle \[\emph{environment} \rightarrow \emph{sensor} \rightarrow \emph{decision} \rightarrow \emph{action} \rightarrow \emph{environment} \dots\]
\end{defin}

\section{Applications of Intelligent Agents} %------------------------------------------------

\begin{itemize_packed}

\item \textbf{Finance}
\begin{itemize}
\item The environment is the market.
\item The sensors indicate the prices.
\item The actuators make trades.
\end{itemize}

\item \textbf{Robotics}
\begin{itemize}
\item The environment is the physical world.
\item The sensors are cameras, microphones, tactile sensors, etc.
\item The actuators are motors, wheels, speakers, etc.
\end{itemize}

\item \textbf{Games}
\begin{enumerate}
\item Chess
\begin{itemize}
\item The environment is the other player (i.e., you).
\item The sensors indicate your moves.
\item The actuators are the robot's moves.
\end{itemize}
\item Video games: the goal is to make the computer player seem "real."
\end{enumerate}

\item \textbf{Medicine}
\newline Called a "Diagnostic Agent." Takes data (the symptoms) from the patient, but gives its analysis to the doctor.

\item \textbf{The World Wide Web}
\newline A Webcrawler.

\begin{center}
\begin{picture}(200,100)
\thicklines
\put(20,20){\line(1,0){70}}
\put(90,20){\line(0,1){70}}
\put(20,20){\line(0,1){70}}
\put(20,90){\line(1,0){70}}
\put(38,92){Crawler}
\put(170,55){\oval(40,90)}
\put(167,74){\begin{rotate}{-90}\large{WWW}\end{rotate}}
\put(158,90){\vector(-4,-1){80}}
\put(100,80){\begin{rotate}{15}Web pages\end{rotate}}

\put(30,40){\usebox{\DB}}
\put(120,0){\usebox{\stickman}}

\put(80,40){\vector(2,-1){30}}
\put(110,10){\vector(-2,1){30}}
\put(80,14){\begin{rotate}{-30}Query\end{rotate}}
\end{picture}
\end{center}

\end{itemize_packed}

\section{Attributes of Environments} % -------------------------------------------------------

\begin{defin}[Fully Observable vs. Partially Observable]
An environment is \emph{\textbf{fully observable}} if the agent can sense enough data at any time to make the optimal decision. It is \emph{\textbf{partially observable}} if not enough information is immediately detectable (via the sensors) to make the optimal decision.
\end{defin}

\textbf{Example:} In poker, not all of the cards are visible. The agent must use memory and/or logic to attempt to guess them.

\begin{defin}[Deterministic vs. Stochastic]
An environment is \emph{\textbf{deterministic}} if the agent's actions uniquely determine the outcome. It is \emph{\textbf{stochastic}} if the outcome of an action is not totally predictable.
\end{defin}

\textbf{Example:} Throwing dice is stochastic, because it involves randomness.

\begin{defin}[Discrete vs. Continuous]
An environment is \emph{\textbf{discrete}} if there are finitely-many action choices, and finitely-many things that can be sensed. It is \emph{\textbf{continuous}} if there are infinitely-many.
\end{defin}

\begin{defin}[Benign vs. Adversarial]
An environment is \emph{\textbf{benign}} if the environment has no objective that would contradict that of the agent. It is \emph{\textbf{adversarial}} if the environment counteracts what the agent is trying to achieve.
\end{defin}

\textbf{Example:} The weather is benign. Chess is adversarial.

%===============================================================================

\part{Problem Solving}

\begin{defin}[Problem]
A problem is defined by the following functions, defined on the sets \textbf{S} of all possible states and \textbf{A} of all possible actions:
\begin{itemize_packed}
\item \emph{Actions} : \textbf{S} $\rightarrow$ \textbf{A} gives all possible actions at the given state.
\item \emph{Result} : (\textbf{S} $\times$ \textbf{A}) $\rightarrow$ \textbf{S} gives the resulting state of applying an action to the given state.
\item \emph{GoalTest} : \textbf{S} $\rightarrow$ \emph{\{true, false\}} indicates if a given state is a goal.
\item \emph{PathCost} : ($s_1\xrightarrow{a_1}s_2\xrightarrow{a_2}s_3$...) $\rightarrow$ $\mathbb{Z}$ indicates the cost of a series of actions. Note that if \emph{PathCost} is additive, then it can be defined simply by \emph{StepCost} : (\textbf{S} $\times$ \textbf{A}) $\rightarrow$ $\mathbb{Z}$, which gives the cost for a single action.
\end{itemize_packed}
\end{defin}

\begin{defin}[Frontier]
The farthest parts that have been \emph{explored} (but not visited!).
\end{defin}

\section{Search algorithms} %-----------------------------------------------------------------

The following algorithm will be studied in this chapter:

\begin{algorithm}
\caption{TreeSearch}
\begin{algorithmic}[1]
\REQUIRE problem
\ENSURE TreeSearch = (Path to goal) or (fail)
\STATE frontier = \{[initial state]\}
\LOOP
	\IF{frontier is empty}
		\RETURN fail
	\ENDIF
	\STATE \label{remove_choice} path = remove\_choice(frontier)
	\STATE s = path.end
	\IF{GoalTest(s)}
		\RETURN path
	\ENDIF
	\FOR{a in Actions(s)}
		\STATE \label{addResult} add Result(s,a) to frontier
	\ENDFOR
\ENDLOOP
\end{algorithmic}
\end{algorithm}

Before going further, an optimization is immediately apparent. The \textbf{GraphSearch} algorithm improves on \textbf{TreeSearch} by eliminating redundant paths (i.e., backtracking). It modifies TreeSearch in the following ways:
\begin{itemize_packed}
\item An extra variable, \emph{explored}, maintains a set of all nodes visited.
\item After calling \emph{remove\_choice} on line \ref{remove_choice}, add \emph{s} to \emph{explored}
\item In the \textbf{for}-loop, do not execute line \ref{addResult} if $Result(s,a) \in explored$ or $frontier$
\end{itemize_packed}

Different choices for how to define the \emph{remove\_choice} function produce different ways to search the tree. We have:

\begin{defin}[Breadth-first search]
\emph{remove\_choice} always returns the state with the \underline{shortest path}.
\end{defin}

\begin{defin}[Uniform-cost aka "cheapest-first" search]
\emph{remove\_choice} always returns the state with the \underline{lowest total cost}.
\end{defin}

\begin{defin}[Depth-first search]
\emph{remove\_choice} always returns the state with the \underline{longest path}.
\end{defin}

Note that:

\begin{itemize_packed}
\item Breadth-first search is optimal, in that it always finds the \textbf{shortest path}.
\item Uniform-cost search is optimal, in that it always finds the \textbf{cheapest path} (assuming that all step costs are strictly positive).
\item Depth-first search is not optimal, but has the advantage of needing less storage space than the others.
\end{itemize_packed}

\begin{defin}[complete]
A \emph{complete} algorithm will always find a solution.
\end{defin}

To improve on the preceding search algorithms, more information is needed. Suppose we have available a heuristic function $h$ : \textbf{S}$\rightarrow\mathbb{R}^+$ that estimates the distance from any state to the goal.

\begin{defin}[Greedy best-first search]
\emph{remove\_choice} always returns the state \underline{closest to the goal}.
\end{defin}

\begin{defin}[A* search]
\emph{remove\_choice} always returns the state with the \underline{minimum value of $f$}. The function $f$ is defined as $f = g + h$, where $g = PathCost$.
\end{defin}

The A* algorithm will find the lowest-cost path \textbf{IF} the distance function $h$ satisfies the condition:
\begin{center}
$h(s)$ $\leq$ the true cost from $s$.
\end{center}
In this case, we say that $h$
\begin{itemize_packed}
\item never over-estimates
\item is \textbf{optimistic}
\item is \textbf{admissible}
\end{itemize_packed}

An admissible heuristic can be derived from a formal statement of a problem by relaxing one or more of the constraints.

\section{Summary} %-----------------------------------------------------------

The techniques of problem-solving discussed in this chapter can be applied when the problem being studied is:
\begin{itemize_packed}
\item fully observable
\item discrete
\item deterministic
\item static (i.e., only the agent can change the state of the environment)
\item the set of all possible actions at any given state is known.
\end{itemize_packed}

\section{A note on implementation} %----------------------------------------------------------

A state is implemented on a computer as a data structure called a \textbf{node}. A node consists of four fields:
\begin{itemize_packed}
\item \textbf{State}: a description of the state of the environment at the end of the path.
\item \textbf{Action}: the action taken to arrive at that state.
\item \textbf{Cost}: the total cost of getting to that state.
\item \textbf{Parent}: a pointer to the previous node in the path
\end{itemize_packed}

\noindent\textbf{Example}: Suppose we have the path
\begin{center}
$A \rightarrow S \rightarrow F$.
\end{center}
This would be implemented with the following nodes:

\begin{center}
\begin{picture}(250,100)
\thicklines

\put(3,49){\textbf{state}}
\put(3,37){\textbf{action}}
\put(3,25){\textbf{cost}}
\put(3,13){\textbf{parent}}

\put(50,10){\usebox{\nodeBox}}
\put(53,49){A}
\put(53,37){$\emptyset$}
\put(53,25){0}
\put(53,13){$\emptyset$}

\put(130,10){\usebox{\nodeBox}}
\put(133,49){S}
\put(133,37){A$\rightarrow$S}
\put(133,25){...}
\put(133,13){A}

\put(210,10){\usebox{\nodeBox}}
\put(213,49){F}
\put(213,37){S$\rightarrow$F}
\put(213,25){...}
\put(213,13){S}

\put(212,16){\vector(-4,1){50}}
\put(132,16){\vector(-4,1){50}}

\end{picture}
\end{center}

In addition,
\begin{itemize_packed}
\item The frontier nodes are best stored as two data structures:
\begin{itemize_packed}
\item A \textbf{priority queue}, since we need to be able to dynamically add new nodes and remove the "best"
\item A \textbf{set}, since we need to be able to check membership.
\end{itemize_packed}
\item The explored nodes are best stored as a \textbf{set}, since we need to dynamically add new nodes and check membership.
\end{itemize_packed}

%===============================================================================

\part{Probability in AI}

\paragraph{Bayes Networks.} In this class, all events are assumed to be \textbf{binary}, i.e. there are only two possible values.

\noindent Consider the following diagram, representing an attempt to diagnose a car that won't start.

\begin{center}
\begin{picture}(300,200)
\thicklines

\put(20,180){Battery}
\put(25,170){Age}
\put(18,166){\framebox(37,24)}

\put(37,166){\vector(0,-1){16}}

\put(20,140){Battery}
\put(23,130){Dead}
\put(18,126){\framebox(37,24)}

\put(37,126){\vector(-1,-4){4}}
\put(39,126){\vector(3,-2){47}}

\put(10,100){Battery}
\put(12,90){Meter}
\put(8,86){\framebox(37,24)}

\put(80,180){Alternator}
\put(85,170){Broken}
\put(78,166){\framebox(49,24)}

\put(108,166){\vector(1,-2){8}}

\put(150,180){Fan belt}
\put(151,170){Broken}
\put(148,166){\framebox(42,24)}

\put(160,166){\vector(-3,-2){24}}

\put(120,140){Not}
\put(110,130){Charging}
\put(108,126){\framebox(42,24)}

\put(129,125){\vector(-2,-3){17}}

\put(90,90){Battery}
\put(94,80){Flat}
\put(88,76){\framebox(37,24)}

\put(100,75){\vector(-3,-2){75}}
\put(103,75){\vector(-1,-1){43}}
\put(106,75){\vector(-1,-4){11}}
\put(109,75){\vector(3,-4){33}}

\put(10,15){Lights}
\put(8,11){\framebox(30,14)}

\put(50,20){Oil}
\put(48,10){Light}
\put(46,6){\framebox(28,24)}

\put(90,20){Gas}
\put(85,10){Gauge}
\put(83,6){\framebox(32,24)}

\put(160,80){No}
\put(159,70){Oil}
\put(157,66){\framebox(20,24)}

\put(167,65){\vector(-3,-1){100}}
\put(170,65){\vector(2,-3){27}}

\put(190,80){No}
\put(189,70){Gas}
\put(187,66){\framebox(20,24)}

\put(198,65){\vector(-3,-1){100}}
\put(200,65){\vector(-3,-2){50}}
\put(202,65){\vector(1,-4){10}}

\put(215,80){Fuel Line}
\put(216,70){Blocked}
\put(213,66){\framebox(46,24)}

\put(230,65){\vector(-2,-1){70}}

\put(267,80){Starter}
\put(267,70){Broken}
\put(265,66){\framebox(40,24)}

\put(270,65){\vector(-3,-1){100}}

\put(190,15){Dipstick}
\put(188,11){\framebox(40,14)}

\color{red}
\put(130,20){Car Won't}
\put(140,10){Start}
\put(128,6){\framebox(50,24)}

\end{picture}
\end{center}

Bayes Networks have many applications, including:
\begin{itemize_packed}
\item Diagnostics
\item Prediction
\item Machine Learning
\item Finance
\item Robotics
\item Web searching
\item Particle filters
\item HMM
\end{itemize_packed}

\paragraph{Probability} Essential to the understanding of Bayes Networks is the theory of probability.

\begin{defin}[Complementary Probability] \quad
\begin{center}
$P(A) = p \iff P(\neg A) = 1-p$
\end{center}
\end{defin}

\begin{defin}[Independence] \quad
\begin{center}
$X \perp Y \implies P(X,Y) = P(X)P(Y)$
\end{center}
\begin{itemize_packed}
\item $X \perp Y$ means $X$ is \emph{\textbf{(absolutely) independent}} of $Y$.
\item $P(X,Y)$ is the \emph{\textbf{Joint Probability}} of $X$ and $Y$.
\item $P(X)$ and $P(Y)$ are the \emph{\textbf{Marginal Probabilities}} of $X$ and $Y$.
\end{itemize_packed}
\end{defin}

\begin{defin}[Total Probability] \quad
\begin{center}
$P(Y) = \displaystyle\sum_i P(Y|X=i)P(X=i)$
\end{center}
\end{defin}

\begin{defin}[Conditional Probability] \quad
\begin{center}
$P(Q|E) = \displaystyle\frac{P(Q,E)}{P(E)}$
\end{center}
\end{defin}

\begin{defin}[Bayes' Rule] \quad
\begin{center}
$P(A|B) = \displaystyle\frac{P(B|A)P(A)}{P(B)}$
\end{center}
\begin{itemize_packed}
\item $P(A|B)$ is called the \emph{\textbf{posterior}}.
\item $P(B|A)$ is called the \emph{\textbf{likelihood}}.
\item $P(A)$ is called the \emph{\textbf{prior}}.
\item $P(B)$ is called the \emph{\textbf{marginal likelihood}}.
\end{itemize_packed}
The marginal likelihood is often expanded using the total probability.
\end{defin}

\begin{defin}[Diagnostic Reasoning] A Bayes Network often has the following form:
\begin{center}
\begin{picture}(90,70)
\thicklines
\put(0,0){\framebox(90,70)}

\put(10,10){B}
\put(14,13){\circle{17}}
\put(28,10){observable}

\put(10,50){A}
\put(27,50){not observable}
\put(15,53){\circle{17}}

\put(14,46){\vector(0,-1){25}}
\end{picture}
\end{center}

\noindent where $P(A)$, $P(B|A)$ and $P(B|\neg A)$ are known. \emph{\textbf{Diagnostic Reasoning}} is the process by which we attempt to find $P(A|B)$ or $P(A|\neg B)$.
\end{defin}

\begin{defin}[Conditional Independence] The variables $A$ and $B$ are \emph{\textbf{Conditionally Independent given $C$}} if
\begin{center}
$P(A|C,B) = P(A,C)$.
\end{center}
\noindent In this case, we write $A \perp B | C$.
\end{defin}

\paragraph{Conditional versus Absolute Independence.} Consider the following two examples:
\begin{center}
\begin{picture}(170,90)
\thicklines

\put(10,20){$T_1$}
\put(15,23){\circle{17}}

\put(50,20){$T_2$}
\put(55,23){\circle{17}}

\put(30,60){$C$}
\put(34,63){\circle{17}}

\put(31,55){\vector(-1,-2){12}}
\put(37,55){\vector(1,-2){12}}

\put(13,1){$T_1 \perp T_2 | C$}


\put(110,60){$S$}
\put(115,63){\circle{17}}

\put(150,60){$R$}
\put(155,63){\circle{17}}

\put(130,20){$H$}
\put(135,23){\circle{17}}

\put(117,55){\vector(1,-2){12}}
\put(153,55){\vector(-1,-2){12}}

\put(122,1){$S \perp R$}

\end{picture}
\end{center}

\noindent The network on the left represents two tests, $T_1$ and $T_2$, used to determine whether a patient has cancer, represented by $C$. The tests $T_1$ and $T_2$ are conditionally independent given $C$: if we already know whether the person has cancer, then knowing the outcome of one test will have no effect on the probability of the other test. However, $T_1$ and $T_2$ are \textbf{not} absolutely independent. If we do not know whether the patient has cancer, then a positive (or negative) result on one test will affect the probability of the other test.

In the network on the right, $S$ represents whether it is sunny outside, $R$ represents whether the professor got a raise, and $H$ represents whether the professor is happy. In this example, $S$ and $R$ are absolutely independent: the weather and the professor's salary have nothing to do with each other. However, $S$ and $R$ are \textbf{not} conditionally independent given $H$. If we know that the professor is happy, then sunny weather could "\textbf{explain away}" his happiness, making a raise less likely.

\paragraph{Advantages of Bayes Networks.} \quad

\begin{picture}(300,100)
\thicklines

\put(5,85){A}
\put(9,88){\circle{17}}

\put(12,80){\vector(2,-3){13}}

\put(45,85){B}
\put(49,88){\circle{17}}

\put(46,80){\vector(-2,-3){13}}

\put(25,50){C}
\put(29,53){\circle{17}}

\put(26,45){\vector(-2,-3){13}}
\put(32,45){\vector(2,-3){13}}

\put(5,15){D}
\put(9,18){\circle{17}}

\put(45,15){E}
\put(49,18){\circle{17}}

\put(80,40){
\begin{tabular}{r l}
Given: & $P(A) \quad P(B)$ \\
 & $P(C|A,B)$ \\
 & $P(D|C) \quad P(E|C)$ \\
Find: & $P(A,B,C,D,E)$ \\
 & $=P(A)P(B)P(C|A,B)P(D|C)P(E|C)$
\end{tabular}
}
\end{picture}

\noindent The advantage of using a Bayes Network to describe this situation, is that calculating $P(A,B,C,D,E)$ only requires 10 variables. Enumerating all the possibilities would require storing $2^5-1 = 31$ different values.

In general, if a node has $k$ incoming arcs, it will require $2^k$ variables.

\paragraph{D-separation, aka Reachability.}

\begin{center}
\begin{picture}(100,50)
\put(10,25){\circle*{17}}
\put(20,22){ = known variable's value}
\end{picture}
\end{center}

\begin{center}
\begin{picture}(260,60)
\thicklines

\put(20,50){\underline{Active Triplets}}
\put(160,50){\underline{Inactive Triplets}}

\put(10,10){\circle{17}}
\put(18,10){\vector(1,0){24}}
\put(50,10){\circle{17}}
\put(58,10){\vector(1,0){24}}
\put(90,10){\circle{17}}

\put(160,10){\circle{17}}
\put(168,10){\vector(1,0){24}}
\put(200,10){\circle*{17}}
\put(208,10){\vector(1,0){24}}
\put(240,10){\circle{17}}

\end{picture}
\end{center}

\begin{center}
\begin{picture}(260,70)
\thicklines

\put(50,53){\circle{17}}
\put(30,18){\circle{17}}
\put(70,18){\circle{17}}

\put(47,45){\vector(-2,-3){13}}
\put(53,45){\vector(2,-3){13}}

\put(200,53){\circle*{17}}
\put(180,18){\circle{17}}
\put(220,18){\circle{17}}

\put(197,45){\vector(-2,-3){13}}
\put(203,45){\vector(2,-3){13}}

\end{picture}
\end{center}

\begin{center}
\begin{picture}(260,60)
\thicklines

\put(30,48){\circle{17}}
\put(70,48){\circle{17}}
\put(50,13){\circle*{17}}

\put(33,40){\vector(2,-3){13}}
\put(67,40){\vector(-2,-3){13}}

\put(180,48){\circle{17}}
\put(220,48){\circle{17}}
\put(200,13){\circle{17}}

\put(183,40){\vector(2,-3){13}}
\put(217,40){\vector(-2,-3){13}}

\end{picture}
\end{center}

\begin{center}
\begin{picture}(260,110)
\thicklines

\put(30,98){\circle{17}}
\put(70,98){\circle{17}}
\put(50,63){\circle{17}}

\put(33,90){\vector(2,-3){13}}
\put(67,90){\vector(-2,-3){13}}
\put(50,55){\vector(0,-1){20}}

\put(50,31){\circle*{1}}
\put(50,27){\circle*{1}}
\put(50,23){\circle*{1}}

\put(50,12){\circle*{17}}

\end{picture}
\end{center}

%===============================================================================

\part{Probabilistic Inference}

Consider the following Bayes network:

\begin{center}
\begin{picture}(150,100)
\thicklines

\put(5,85){B}
\put(9,88){\circle{17}}

\put(12,80){\vector(2,-3){13}}

\put(45,85){E}
\put(49,88){\circle{17}}

\put(46,80){\vector(-2,-3){13}}

\put(25,50){A}
\put(29,53){\circle{17}}

\put(26,45){\vector(-2,-3){13}}
\put(32,45){\vector(2,-3){13}}

\put(5,15){J}
\put(9,18){\circle{17}}

\put(45,15){M}
\put(49,18){\circle{17}}

\put(80,80){B = burglary}
\put(80,65){E = earthquake}
\put(80,50){A = alarm went off}
\put(80,35){J = John was called}
\put(80,20){M = Mary was called}
\end{picture}
\end{center}

\noindent Typically, a computer function would take B and E as the input, and calculate J and M as the output. In this case,

\begin{tabular}{r c l c}
B and E & are called the & \textbf{evidence} & (known) \\
J and M & are called the & \textbf{query} & (desired) \\
A & is & \textbf{hidden} & (required for computations)
\end{tabular}

\begin{defin}[Posterior Distribution]
$P(Q_1,Q_2,...|E_1=e_1, E_2=e_2, ...)$. The variables $Q_i$ are called the \emph{\textbf{query variables}}, and the $E_j$ are called the \emph{\textbf{evidence variables}}.
\end{defin}

We define
\begin{center}
$argmax_q P(Q_1=q_1, ... | E_1=e_1, ...)$
\end{center}
\noindent to be the combination of values with the highest probability.

\paragraph{Enumeration.} We start with the question, what is $P(+b | +j, +m)$? From the formula for conditional probability, this is equivalent to
\begin{center}
$\displaystyle\frac{P(+b,+j,+m)}{P(+j,+m)}$
\end{center}
\noindent We then enumerate the atomic probabilities, and calculate the sum of the products.
\begin{center}
\begin{align*}
P(+b,+j,+m) & = \sum_e\sum_aP(+b,+j,+m) \\
 & = \sum_e\sum_a\underbrace{P(+b)P(e)P(a|+b,e)P(+j|a)P(+m|a)}_{f(e,a)} \\
 & = f(+e,+a) + f(+e,\neg a) + f(\neg e,+a) + f(\neg e, \neg a).
\end{align*}
\end{center}
\noindent The problem with this method is that it quickly becomes impractical for even moderately-sized networks. $f$ can be optimized somewhat:
\begin{center}
$\displaystyle f(e,a) = P(+b)\sum_eP(e)\sum_aP(a|+b,e)P(+j|a)P(+m|a)$
\end{center}
\noindent but this is not sufficient.

\paragraph{Maximizing independence.} Consider the following networks:

\begin{center}
\begin{picture}(250,100)
\thicklines
\put(35,90){\underline{Network}}
\put(150,90){\underline{Time to compute}}

\put(10,70){$x_1$}
\put(15,72){\circle{17}}

\put(23,72){\line(1,0){13}}

\put(40,70){$x_2$}
\put(45,72){\circle{17}}

\put(53,72){\line(1,0){13}}

\put(70,70){\dots}

\put(83,72){\line(1,0){13}}

\put(100,70){$x_n$}
\put(105,72){\circle{17}}

\put(180,70){$O(n)$}


\put(10,20){$x_1$}
\put(15,22){\circle{17}}

\put(23,22){\line(1,0){13}}
\qbezier(21,28)(30,32)(38,28)
\qbezier(20,30)(50,40)(72,26)
\qbezier(18,31)(60,50)(98,28)

\put(40,20){$x_2$}
\put(45,22){\circle{17}}

\put(53,22){\line(1,0){13}}
\qbezier(51,17)(60,12)(72,17)
\qbezier(49,15)(75,0)(99,16)

\put(70,20){\dots}

\put(83,22){\line(1,0){13}}
\qbezier(76,17)(86,10)(97,18)

\put(100,20){$x_n$}
\put(105,22){\circle{17}}

\put(180,20){$O(2^n)$}

\end{picture}
\end{center}

\noindent In the first network, there is only one edge between each node. In the second, every node has an edge with every other node. This gives us bounds for best- and worst-case run-time.

Bayes networks are the easiest to use when they are directed in the \textbf{causal direction}, i.e. when the network flows from causes to effects.

\paragraph{Variable elimination.} Another way to optimize $f$ that is faster than enumeration, is the following. Consider the follwing network:

\begin{center}
\begin{picture}(100,25)
\thicklines

\put(10,10){$R$}
\put(15,13){\circle{17}}

\put(23,13){\vector(1,0){13}}

\put(40,10){$T$}
\put(45,13){\circle{17}}

\put(53,13){\vector(1,0){13}}

\put(70,10){$L$}
\put(75,13){\circle{17}}

\end{picture}
\end{center}

\noindent where $R$ represents rain, $T$ represents heavy traffic, and $L$ represents the student being late to class. We know the probabilities $P(R)$, $P(T|R)$, and $P(L|T)$, for all possible values $r$, $t$, and $l$. We perform the following steps:

\begin{enumerate}
\item \textbf{Joining factors}: combine $R$ and $T$ into $P(R,T) = P(T|R)P(R)$
\item Sum over $R$ to eliminate $R$, leaving $T$:
\begin{align*}
P(+t) & = P(+t,+r) + P(+t,\neg r) \\
P(\neg t) & = P(\neg t,+r) + P(\neg t, \neg r)
\end{align*}
\item Join the factors $T$ and $L$.
\item Sum over $T$ to elimnate $T$, leaving $L$.
\end{enumerate}

\end{document}